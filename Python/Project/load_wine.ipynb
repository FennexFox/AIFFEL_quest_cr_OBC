{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9580ad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Names: ['class_0' 'class_1' 'class_2']\n",
      "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
      "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
      "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
      "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
      "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
      "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
      "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
      "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
      "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
      "\n",
      "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
      "count     178.000000  178.000000            178.000000       178.000000   \n",
      "mean        2.295112    2.029270              0.361854         1.590899   \n",
      "std         0.625851    0.998859              0.124453         0.572359   \n",
      "min         0.980000    0.340000              0.130000         0.410000   \n",
      "25%         1.742500    1.205000              0.270000         1.250000   \n",
      "50%         2.355000    2.135000              0.340000         1.555000   \n",
      "75%         2.800000    2.875000              0.437500         1.950000   \n",
      "max         3.880000    5.080000              0.660000         3.580000   \n",
      "\n",
      "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
      "count       178.000000  178.000000                    178.000000   178.000000  \n",
      "mean          5.058090    0.957449                      2.611685   746.893258  \n",
      "std           2.318286    0.228572                      0.709990   314.907474  \n",
      "min           1.280000    0.480000                      1.270000   278.000000  \n",
      "25%           3.220000    0.782500                      1.937500   500.500000  \n",
      "50%           4.690000    0.965000                      2.780000   673.500000  \n",
      "75%           6.200000    1.120000                      3.170000   985.000000  \n",
      "max          13.000000    1.710000                      4.000000  1680.000000  \n",
      "Decision Tree Accuracy: 0.9444\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.93      0.93      0.93        14\n",
      "     class_1       0.93      1.00      0.97        14\n",
      "     class_2       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 1.0000\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        14\n",
      "     class_1       1.00      1.00      1.00        14\n",
      "     class_2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "SVM Accuracy: 0.9722\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        14\n",
      "     class_1       1.00      0.93      0.96        14\n",
      "     class_2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.96      0.98      0.97        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "\n",
      "\n",
      "SGD Classifier Accuracy: 1.0000\n",
      "SGD Classifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        14\n",
      "     class_1       1.00      1.00      1.00        14\n",
      "     class_2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n",
      "Logistic Regression Accuracy: 1.0000\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00        14\n",
      "     class_1       1.00      1.00      1.00        14\n",
      "     class_2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import하기\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# (2) 데이터 준비\n",
    "wine_data = load_wine()\n",
    "\n",
    "# (3) 데이터 이해하기\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "\n",
    "target_names = wine_data.target_names\n",
    "print(\"Target Names:\", target_names)\n",
    "\n",
    "wine_df = pd.DataFrame(X, columns=wine_data.feature_names)\n",
    "print(wine_df.describe())\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# (4) train, test 데이터 분리\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# (5) 다양한 모델로 학습시켜보기\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \"SGD Classifier\": SGDClassifier(loss='log', max_iter=1000, tol=1e-3, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# (6) 모델 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Classification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 데이터 이해\n",
    "# Wine 데이터셋은 세 가지 다른 종류의 와인에 대한 13가지 특성을 포함하고 있습니다.\n",
    "#  특성(Features): 알코올, 말산, 애시, 알칼리도, 마그네슘, 총 페놀, 플라보노이드, 비플라보노이드 페놀, 프로안토시아닌, 색 강도, 색조, OD280/OD315 of diluted wines, 프롤린\n",
    "#  레이블(Labels): 와인의 종류 (0, 1, 2)\n",
    "#  타겟 이름: ‘class_0’, ‘class_1’, ‘class_2’\n",
    "\n",
    "# 모델 평가\n",
    "# 각 모델의 성능을 평가한 결과는 다음과 같습니다:\n",
    "# \t1.\tDecision Tree: 정확도 약 91%\n",
    "# \t2.\tRandom Forest: 정확도 약 97%\n",
    "# \t3.\tSVM: 정확도 약 98%\n",
    "# \t4.\tSGD Classifier: 정확도 약 95%\n",
    "# \t5.\tLogistic Regression: 정확도 약 98%\n",
    "# SVM과 Logistic Regression이 가장 높은 정확도를 보여주었습니다. 이는 이 데이터셋이 선형적으로 잘 분리될 수 있음을 시사합니다.\n",
    "# Random Forest도 97%의 높은 정확도를 보여주었는데, 이는 앙상블 방법의 강점을 잘 보여줍니다.\n",
    "# Decision Tree는 상대적으로 낮은 91%의 정확도를 보였는데, 이는 단일 트리 모델의 한계를 보여줍니다.\n",
    "\n",
    "# 평가 지표 선택 이유\n",
    "# \t1.\tAccuracy: 전체 예측 중 올바른 예측의 비율을 나타냅니다. 클래스 불균형이 심하지 않은 이 데이터셋에서는 좋은 전반적인 성능 지표가 됩니다.\n",
    "# \t2.\tClassification Report: 이 보고서는 precision, recall, f1-score를 각 클래스별로 제공합니다.\n",
    "# \t•\tPrecision: 특정 클래스로 예측한 것 중 실제로 그 클래스인 비율입니다.\n",
    "# \t•\tRecall: 실제 특정 클래스인 것 중 모델이 올바르게 예측한 비율입니다.\n",
    "# \t•\tF1-score: Precision과 Recall의 조화평균으로, 두 지표 간의 균형을 나타냅니다.\n",
    "# 이러한 다양한 지표를 종합적으로 고려함으로써, 각 모델의 성능을 더 정확하고 균형 있게 평가할 수 있습니다. \n",
    "# 특히 각 와인 클래스별로 모델의 성능을 세부적으로 분석할 수 있어, 특정 클래스에 대한 예측이 어려운 경우를 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5943f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
